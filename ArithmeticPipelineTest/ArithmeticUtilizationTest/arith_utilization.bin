//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19659101
// Driver 352.21
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_30, texmode_independent
.address_size 64


.entry Integer_addition_0_20(
	.param .u64 .ptr .global .align 4 Integer_addition_0_20_param_0,
	.param .u32 Integer_addition_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_0_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_0_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r9, %r9, %r8;
	add.s32 	%r10, %r10, %r8;
	add.s32 	%r11, %r11, %r8;
	add.s32 	%r12, %r12, %r8;
	add.s32 	%r13, %r13, %r8;
    add.s32 	%r14, %r14, %r8;
	add.s32 	%r15, %r15, %r8;
	add.s32 	%r16, %r16, %r8;
	add.s32 	%r17, %r17, %r8;
	add.s32 	%r18, %r18, %r8;
	add.s32 	%r19, %r19, %r8;
	add.s32 	%r20, %r20, %r8;
	add.s32 	%r21, %r21, %r8;
	add.s32 	%r22, %r22, %r8;
	add.s32 	%r23, %r23, %r8;
	add.s32 	%r24, %r24, %r8;
	add.s32 	%r25, %r25, %r8;
	add.s32 	%r26, %r26, %r8;
	add.s32 	%r27, %r27, %r8;
	add.s32 	%r30, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_0_20(
	.param .u64 .ptr .global .align 8 Double_addition_0_20_param_0,
	.param .u32 Double_addition_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_0_20_param_0];
	ld.param.u32 	%r4, [Double_addition_0_20_param_1];
    ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd6, %fd6, %fd25;
	add.f64 	%fd7, %fd7, %fd25;
	add.f64 	%fd8, %fd8, %fd25;
	add.f64 	%fd9, %fd9, %fd25;
	add.f64 	%fd10, %fd10, %fd25;
	add.f64 	%fd11, %fd11, %fd25;
	add.f64 	%fd12, %fd12, %fd25;
	add.f64 	%fd13, %fd13, %fd25;
	add.f64 	%fd14, %fd14, %fd25;
	add.f64 	%fd15, %fd15, %fd25;
	add.f64 	%fd16, %fd16, %fd25;
	add.f64 	%fd17, %fd17, %fd25;
	add.f64 	%fd18, %fd18, %fd25;
	add.f64 	%fd19, %fd19, %fd25;
	add.f64 	%fd20, %fd20, %fd25;
	add.f64 	%fd21, %fd21, %fd25;
	add.f64 	%fd22, %fd22, %fd25;
	add.f64 	%fd23, %fd23, %fd25;
	add.f64 	%fd24, %fd24, %fd25;
	add.f64 	%fd27, %fd27, %fd25;
    shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_0_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_0_20_param_0,
	.param .u32 Integer_multiplication_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_0_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_0_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r9, %r9, %r8;
	mul.lo.s32 	%r10, %r10, %r8;
	mul.lo.s32 	%r11, %r11, %r8;
	mul.lo.s32 	%r12, %r12, %r8;
	mul.lo.s32 	%r13, %r13, %r8;
    mul.lo.s32 	%r14, %r14, %r8;
	mul.lo.s32 	%r15, %r15, %r8;
	mul.lo.s32 	%r16, %r16, %r8;
	mul.lo.s32 	%r17, %r17, %r8;
	mul.lo.s32 	%r18, %r18, %r8;
	mul.lo.s32 	%r19, %r19, %r8;
	mul.lo.s32 	%r20, %r20, %r8;
	mul.lo.s32 	%r21, %r21, %r8;
	mul.lo.s32 	%r22, %r22, %r8;
	mul.lo.s32 	%r23, %r23, %r8;
	mul.lo.s32 	%r24, %r24, %r8;
	mul.lo.s32 	%r25, %r25, %r8;
	mul.lo.s32 	%r26, %r26, %r8;
	mul.lo.s32 	%r27, %r27, %r8;
	mul.lo.s32 	%r30, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_0_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_0_20_param_0,
	.param .u32 Double_multiplication_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_0_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_0_20_param_1];
    ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd6, %fd6, %fd25;
	mul.f64 	%fd7, %fd7, %fd25;
	mul.f64 	%fd8, %fd8, %fd25;
	mul.f64 	%fd9, %fd9, %fd25;
	mul.f64 	%fd10, %fd10, %fd25;
	mul.f64 	%fd11, %fd11, %fd25;
	mul.f64 	%fd12, %fd12, %fd25;
	mul.f64 	%fd13, %fd13, %fd25;
	mul.f64 	%fd14, %fd14, %fd25;
	mul.f64 	%fd15, %fd15, %fd25;
	mul.f64 	%fd16, %fd16, %fd25;
	mul.f64 	%fd17, %fd17, %fd25;
	mul.f64 	%fd18, %fd18, %fd25;
	mul.f64 	%fd19, %fd19, %fd25;
	mul.f64 	%fd20, %fd20, %fd25;
	mul.f64 	%fd21, %fd21, %fd25;
	mul.f64 	%fd22, %fd22, %fd25;
	mul.f64 	%fd23, %fd23, %fd25;
	mul.f64 	%fd24, %fd24, %fd25;
	mul.f64 	%fd27, %fd27, %fd25;
    shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_5_20(
	.param .u64 .ptr .global .align 4 Integer_addition_5_20_param_0,
	.param .u32 Integer_addition_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_5_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_5_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r13, %r9, %r8;
	add.s32 	%r14, %r10, %r8;
	add.s32 	%r15, %r11, %r8;
	add.s32 	%r16, %r12, %r8;
	add.s32 	%r17, %r13, %r8;
    add.s32 	%r18, %r14, %r8;
	add.s32 	%r19, %r15, %r8;
	add.s32 	%r20, %r16, %r8;
	add.s32 	%r21, %r17, %r8;
	add.s32 	%r22, %r18, %r8;
	add.s32 	%r23, %r19, %r8;
	add.s32 	%r24, %r20, %r8;
	add.s32 	%r25, %r21, %r8;
	add.s32 	%r26, %r22, %r8;
	add.s32 	%r27, %r23, %r8;
	add.s32 	%r30, %r24, %r8;
	add.s32 	%r9, %r25, %r8;
	add.s32 	%r10, %r26, %r8;
	add.s32 	%r11, %r27, %r8;
	add.s32 	%r12, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_5_20(
	.param .u64 .ptr .global .align 8 Double_addition_5_20_param_0,
	.param .u32 Double_addition_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_5_20_param_0];
	ld.param.u32 	%r4, [Double_addition_5_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd10, %fd6, %fd25;
	add.f64 	%fd11, %fd7, %fd25;
	add.f64 	%fd12, %fd8, %fd25;
	add.f64 	%fd13, %fd9, %fd25;
	add.f64 	%fd14, %fd10, %fd25;
	add.f64 	%fd15, %fd11, %fd25;
	add.f64 	%fd16, %fd12, %fd25;
	add.f64 	%fd17, %fd13, %fd25;
	add.f64 	%fd18, %fd14, %fd25;
	add.f64 	%fd19, %fd15, %fd25;
	add.f64 	%fd20, %fd16, %fd25;
	add.f64 	%fd21, %fd17, %fd25;
	add.f64 	%fd22, %fd18, %fd25;
	add.f64 	%fd23, %fd19, %fd25;
	add.f64 	%fd24, %fd20, %fd25;
	add.f64 	%fd27, %fd21, %fd25;
	add.f64 	%fd6, %fd22, %fd25;
	add.f64 	%fd7, %fd23, %fd25;
	add.f64 	%fd8, %fd24, %fd25;
	add.f64 	%fd9, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_5_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_5_20_param_0,
	.param .u32 Integer_multiplication_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_5_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_5_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r13, %r9, %r8;
	mul.lo.s32 	%r14, %r10, %r8;
	mul.lo.s32 	%r15, %r11, %r8;
	mul.lo.s32 	%r16, %r12, %r8;
	mul.lo.s32 	%r17, %r13, %r8;
    mul.lo.s32 	%r18, %r14, %r8;
	mul.lo.s32 	%r19, %r15, %r8;
	mul.lo.s32 	%r20, %r16, %r8;
	mul.lo.s32 	%r21, %r17, %r8;
	mul.lo.s32 	%r22, %r18, %r8;
	mul.lo.s32 	%r23, %r19, %r8;
	mul.lo.s32 	%r24, %r20, %r8;
	mul.lo.s32 	%r25, %r21, %r8;
	mul.lo.s32 	%r26, %r22, %r8;
	mul.lo.s32 	%r27, %r23, %r8;
	mul.lo.s32 	%r30, %r24, %r8;
	mul.lo.s32 	%r9, %r25, %r8;
	mul.lo.s32 	%r10, %r26, %r8;
	mul.lo.s32 	%r11, %r27, %r8;
	mul.lo.s32 	%r12, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_5_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_5_20_param_0,
	.param .u32 Double_multiplication_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_5_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_5_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd10, %fd6, %fd25;
	mul.f64 	%fd11, %fd7, %fd25;
	mul.f64 	%fd12, %fd8, %fd25;
	mul.f64 	%fd13, %fd9, %fd25;
	mul.f64 	%fd14, %fd10, %fd25;
	mul.f64 	%fd15, %fd11, %fd25;
	mul.f64 	%fd16, %fd12, %fd25;
	mul.f64 	%fd17, %fd13, %fd25;
	mul.f64 	%fd18, %fd14, %fd25;
	mul.f64 	%fd19, %fd15, %fd25;
	mul.f64 	%fd20, %fd16, %fd25;
	mul.f64 	%fd21, %fd17, %fd25;
	mul.f64 	%fd22, %fd18, %fd25;
	mul.f64 	%fd23, %fd19, %fd25;
	mul.f64 	%fd24, %fd20, %fd25;
	mul.f64 	%fd27, %fd21, %fd25;
	mul.f64 	%fd6, %fd22, %fd25;
	mul.f64 	%fd7, %fd23, %fd25;
	mul.f64 	%fd8, %fd24, %fd25;
	mul.f64 	%fd9, %fd27, %fd25;
    shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_7_20(
	.param .u64 .ptr .global .align 4 Integer_addition_7_20_param_0,
	.param .u32 Integer_addition_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_7_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_7_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r11, %r9, %r8;
	add.s32 	%r12, %r10, %r8;
	add.s32 	%r13, %r11, %r8;
	add.s32 	%r14, %r12, %r8;
	add.s32 	%r15, %r13, %r8;
    add.s32 	%r16, %r14, %r8;
	add.s32 	%r17, %r15, %r8;
	add.s32 	%r18, %r16, %r8;
	add.s32 	%r19, %r17, %r8;
	add.s32 	%r20, %r18, %r8;
	add.s32 	%r24, %r19, %r8;
	add.s32 	%r25, %r20, %r8;
	add.s32 	%r26, %r21, %r8;
	add.s32 	%r27, %r22, %r8;
	add.s32 	%r30, %r23, %r8;
	add.s32 	%r9, %r24, %r8;
	add.s32 	%r10, %r25, %r8;
	add.s32 	%r11, %r26, %r8;
	add.s32 	%r12, %r27, %r8;
	add.s32 	%r13, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_7_20(
	.param .u64 .ptr .global .align 8 Double_addition_7_20_param_0,
	.param .u32 Double_addition_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_7_20_param_0];
	ld.param.u32 	%r4, [Double_addition_7_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd8, %fd6, %fd25;
	add.f64 	%fd9, %fd7, %fd25;
	add.f64 	%fd10, %fd8, %fd25;
	add.f64 	%fd11, %fd9, %fd25;
	add.f64 	%fd12, %fd10, %fd25;
	add.f64 	%fd13, %fd11, %fd25;
	add.f64 	%fd14, %fd12, %fd25;
	add.f64 	%fd15, %fd13, %fd25;
	add.f64 	%fd16, %fd14, %fd25;
	add.f64 	%fd17, %fd15, %fd25;
	add.f64 	%fd21, %fd16, %fd25;
	add.f64 	%fd22, %fd17, %fd25;
	add.f64 	%fd23, %fd18, %fd25;
	add.f64 	%fd24, %fd19, %fd25;
	add.f64 	%fd27, %fd20, %fd25;
	add.f64 	%fd6, %fd21, %fd25;
	add.f64 	%fd7, %fd22, %fd25;
	add.f64 	%fd8, %fd23, %fd25;
	add.f64 	%fd9, %fd24, %fd25;
	add.f64 	%fd10, %fd27, %fd25;
    shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_7_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_7_20_param_0,
	.param .u32 Integer_multiplication_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_7_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_7_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r11, %r9, %r8;
	mul.lo.s32 	%r12, %r10, %r8;
	mul.lo.s32 	%r13, %r11, %r8;
	mul.lo.s32 	%r14, %r12, %r8;
	mul.lo.s32 	%r15, %r13, %r8;
    mul.lo.s32 	%r16, %r14, %r8;
	mul.lo.s32 	%r17, %r15, %r8;
	mul.lo.s32 	%r18, %r16, %r8;
	mul.lo.s32 	%r19, %r17, %r8;
	mul.lo.s32 	%r20, %r18, %r8;
	mul.lo.s32 	%r24, %r19, %r8;
	mul.lo.s32 	%r25, %r20, %r8;
	mul.lo.s32 	%r26, %r21, %r8;
	mul.lo.s32 	%r27, %r22, %r8;
	mul.lo.s32 	%r30, %r23, %r8;
	mul.lo.s32 	%r9, %r24, %r8;
	mul.lo.s32 	%r10, %r25, %r8;
	mul.lo.s32 	%r11, %r26, %r8;
	mul.lo.s32 	%r12, %r27, %r8;
	mul.lo.s32 	%r13, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_7_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_7_20_param_0,
	.param .u32 Double_multiplication_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_7_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_7_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd8, %fd6, %fd25;
	mul.f64 	%fd9, %fd7, %fd25;
	mul.f64 	%fd10, %fd8, %fd25;
	mul.f64 	%fd11, %fd9, %fd25;
	mul.f64 	%fd12, %fd10, %fd25;
	mul.f64 	%fd13, %fd11, %fd25;
	mul.f64 	%fd14, %fd12, %fd25;
	mul.f64 	%fd15, %fd13, %fd25;
	mul.f64 	%fd16, %fd14, %fd25;
	mul.f64 	%fd17, %fd15, %fd25;
	mul.f64 	%fd21, %fd16, %fd25;
	mul.f64 	%fd22, %fd17, %fd25;
	mul.f64 	%fd23, %fd18, %fd25;
	mul.f64 	%fd24, %fd19, %fd25;
	mul.f64 	%fd27, %fd20, %fd25;
	mul.f64 	%fd6, %fd21, %fd25;
	mul.f64 	%fd7, %fd22, %fd25;
	mul.f64 	%fd8, %fd23, %fd25;
	mul.f64 	%fd9, %fd24, %fd25;
	mul.f64 	%fd10, %fd27, %fd25;
    shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_10_20(
	.param .u64 .ptr .global .align 4 Integer_addition_10_20_param_0,
	.param .u32 Integer_addition_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_10_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_10_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r11, %r9, %r8;
	add.s32 	%r12, %r10, %r8;
	add.s32 	%r13, %r11, %r8;
	add.s32 	%r14, %r12, %r8;
	add.s32 	%r15, %r13, %r8;
    add.s32 	%r16, %r14, %r8;
	add.s32 	%r17, %r15, %r8;
	add.s32 	%r18, %r16, %r8;
	add.s32 	%r19, %r17, %r8;
	add.s32 	%r20, %r18, %r8;
	add.s32 	%r21, %r19, %r8;
	add.s32 	%r22, %r20, %r8;
	add.s32 	%r23, %r21, %r8;
	add.s32 	%r24, %r22, %r8;
	add.s32 	%r25, %r23, %r8;
	add.s32 	%r26, %r24, %r8;
	add.s32 	%r27, %r25, %r8;
	add.s32 	%r30, %r26, %r8;
	add.s32 	%r9, %r27, %r8;
	add.s32 	%r10, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_10_20(
	.param .u64 .ptr .global .align 8 Double_addition_10_20_param_0,
	.param .u32 Double_addition_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_10_20_param_0];
	ld.param.u32 	%r4, [Double_addition_10_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd8, %fd6, %fd25;
	add.f64 	%fd9, %fd7, %fd25;
	add.f64 	%fd10, %fd8, %fd25;
	add.f64 	%fd11, %fd9, %fd25;
	add.f64 	%fd12, %fd10, %fd25;
	add.f64 	%fd13, %fd11, %fd25;
	add.f64 	%fd14, %fd12, %fd25;
	add.f64 	%fd15, %fd13, %fd25;
	add.f64 	%fd16, %fd14, %fd25;
	add.f64 	%fd17, %fd15, %fd25;
	add.f64 	%fd18, %fd16, %fd25;
	add.f64 	%fd19, %fd17, %fd25;
	add.f64 	%fd20, %fd18, %fd25;
	add.f64 	%fd21, %fd19, %fd25;
	add.f64 	%fd22, %fd20, %fd25;
	add.f64 	%fd23, %fd21, %fd25;
	add.f64 	%fd24, %fd22, %fd25;
	add.f64 	%fd27, %fd23, %fd25;
	add.f64 	%fd6, %fd24, %fd25;
	add.f64 	%fd7, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_10_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_10_20_param_0,
	.param .u32 Integer_multiplication_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_10_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_10_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r11, %r9, %r8;
	mul.lo.s32 	%r12, %r10, %r8;
	mul.lo.s32 	%r13, %r11, %r8;
	mul.lo.s32 	%r14, %r12, %r8;
	mul.lo.s32 	%r15, %r13, %r8;
    mul.lo.s32 	%r16, %r14, %r8;
	mul.lo.s32 	%r17, %r15, %r8;
	mul.lo.s32 	%r18, %r16, %r8;
	mul.lo.s32 	%r19, %r17, %r8;
	mul.lo.s32 	%r20, %r18, %r8;
	mul.lo.s32 	%r21, %r19, %r8;
	mul.lo.s32 	%r22, %r20, %r8;
	mul.lo.s32 	%r23, %r21, %r8;
	mul.lo.s32 	%r24, %r22, %r8;
	mul.lo.s32 	%r25, %r23, %r8;
	mul.lo.s32 	%r26, %r24, %r8;
	mul.lo.s32 	%r27, %r25, %r8;
	mul.lo.s32 	%r30, %r26, %r8;
	mul.lo.s32 	%r9, %r27, %r8;
	mul.lo.s32 	%r10, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
    add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_10_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_10_20_param_0,
	.param .u32 Double_multiplication_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_10_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_10_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd8, %fd6, %fd25;
	mul.f64 	%fd9, %fd7, %fd25;
	mul.f64 	%fd10, %fd8, %fd25;
	mul.f64 	%fd11, %fd9, %fd25;
	mul.f64 	%fd12, %fd10, %fd25;
	mul.f64 	%fd13, %fd11, %fd25;
	mul.f64 	%fd14, %fd12, %fd25;
	mul.f64 	%fd15, %fd13, %fd25;
	mul.f64 	%fd16, %fd14, %fd25;
	mul.f64 	%fd17, %fd15, %fd25;
	mul.f64 	%fd18, %fd16, %fd25;
	mul.f64 	%fd19, %fd17, %fd25;
	mul.f64 	%fd20, %fd18, %fd25;
	mul.f64 	%fd21, %fd19, %fd25;
	mul.f64 	%fd22, %fd20, %fd25;
	mul.f64 	%fd23, %fd21, %fd25;
	mul.f64 	%fd24, %fd22, %fd25;
	mul.f64 	%fd27, %fd23, %fd25;
	mul.f64 	%fd6, %fd24, %fd25;
	mul.f64 	%fd7, %fd27, %fd25;
    shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_12_20(
	.param .u64 .ptr .global .align 4 Integer_addition_12_20_param_0,
	.param .u32 Integer_addition_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_12_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_12_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r24, %r19, %r8;
	add.s32 	%r25, %r20, %r8;
	add.s32 	%r26, %r21, %r8;
	add.s32 	%r27, %r22, %r8;
	add.s32 	%r30, %r23, %r8;
	add.s32 	%r9, %r24, %r8;
	add.s32 	%r10, %r25, %r8;
	add.s32 	%r11, %r26, %r8;
	add.s32 	%r12, %r27, %r8;
	add.s32 	%r13, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_12_20(
	.param .u64 .ptr .global .align 8 Double_addition_12_20_param_0,
	.param .u32 Double_addition_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_12_20_param_0];
	ld.param.u32 	%r4, [Double_addition_12_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd21, %fd16, %fd25;
	add.f64 	%fd22, %fd17, %fd25;
	add.f64 	%fd23, %fd18, %fd25;
	add.f64 	%fd24, %fd19, %fd25;
	add.f64 	%fd27, %fd20, %fd25;
	add.f64 	%fd6, %fd21, %fd25;
	add.f64 	%fd7, %fd22, %fd25;
	add.f64 	%fd8, %fd23, %fd25;
	add.f64 	%fd9, %fd24, %fd25;
	add.f64 	%fd10, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_12_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_12_20_param_0,
	.param .u32 Integer_multiplication_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_12_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_12_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r24, %r19, %r8;
	mul.lo.s32 	%r25, %r20, %r8;
	mul.lo.s32 	%r26, %r21, %r8;
	mul.lo.s32 	%r27, %r22, %r8;
	mul.lo.s32 	%r30, %r23, %r8;
	mul.lo.s32 	%r9, %r24, %r8;
	mul.lo.s32 	%r10, %r25, %r8;
	mul.lo.s32 	%r11, %r26, %r8;
	mul.lo.s32 	%r12, %r27, %r8;
	mul.lo.s32 	%r13, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_12_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_12_20_param_0,
	.param .u32 Double_multiplication_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_12_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_12_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd21, %fd16, %fd25;
	mul.f64 	%fd22, %fd17, %fd25;
	mul.f64 	%fd23, %fd18, %fd25;
	mul.f64 	%fd24, %fd19, %fd25;
	mul.f64 	%fd27, %fd20, %fd25;
	mul.f64 	%fd6, %fd21, %fd25;
	mul.f64 	%fd7, %fd22, %fd25;
	mul.f64 	%fd8, %fd23, %fd25;
	mul.f64 	%fd9, %fd24, %fd25;
	mul.f64 	%fd10, %fd27, %fd25;
	shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_15_20(
	.param .u64 .ptr .global .align 4 Integer_addition_15_20_param_0,
	.param .u32 Integer_addition_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_15_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_15_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r21, %r19, %r8;
	add.s32 	%r22, %r20, %r8;
	add.s32 	%r23, %r21, %r8;
	add.s32 	%r24, %r22, %r8;
	add.s32 	%r25, %r23, %r8;
	add.s32 	%r26, %r24, %r8;
	add.s32 	%r27, %r25, %r8;
	add.s32 	%r30, %r26, %r8;
	add.s32 	%r9, %r27, %r8;
	add.s32 	%r10, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_15_20(
	.param .u64 .ptr .global .align 8 Double_addition_15_20_param_0,
	.param .u32 Double_addition_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_15_20_param_0];
	ld.param.u32 	%r4, [Double_addition_15_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd18, %fd16, %fd25;
	add.f64 	%fd19, %fd17, %fd25;
	add.f64 	%fd20, %fd18, %fd25;
	add.f64 	%fd21, %fd19, %fd25;
	add.f64 	%fd22, %fd20, %fd25;
	add.f64 	%fd23, %fd21, %fd25;
	add.f64 	%fd24, %fd22, %fd25;
	add.f64 	%fd27, %fd23, %fd25;
	add.f64 	%fd6, %fd24, %fd25;
	add.f64 	%fd7, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_15_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_15_20_param_0,
	.param .u32 Integer_multiplication_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_15_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_15_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r21, %r19, %r8;
	mul.lo.s32 	%r22, %r20, %r8;
	mul.lo.s32 	%r23, %r21, %r8;
	mul.lo.s32 	%r24, %r22, %r8;
	mul.lo.s32 	%r25, %r23, %r8;
	mul.lo.s32 	%r26, %r24, %r8;
	mul.lo.s32 	%r27, %r25, %r8;
	mul.lo.s32 	%r30, %r26, %r8;
	mul.lo.s32 	%r9, %r27, %r8;
	mul.lo.s32 	%r10, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_15_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_15_20_param_0,
	.param .u32 Double_multiplication_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_15_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_15_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd18, %fd16, %fd25;
	mul.f64 	%fd19, %fd17, %fd25;
	mul.f64 	%fd20, %fd18, %fd25;
	mul.f64 	%fd21, %fd19, %fd25;
	mul.f64 	%fd22, %fd20, %fd25;
	mul.f64 	%fd23, %fd21, %fd25;
	mul.f64 	%fd24, %fd22, %fd25;
	mul.f64 	%fd27, %fd23, %fd25;
	mul.f64 	%fd6, %fd24, %fd25;
	mul.f64 	%fd7, %fd27, %fd25;
    shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_20_20(
	.param .u64 .ptr .global .align 4 Integer_addition_20_20_param_0,
	.param .u32 Integer_addition_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_20_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_20_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r20, %r19, %r8;
	add.s32 	%r21, %r20, %r8;
	add.s32 	%r22, %r21, %r8;
	add.s32 	%r23, %r22, %r8;
	add.s32 	%r24, %r23, %r8;
	add.s32 	%r25, %r24, %r8;
	add.s32 	%r26, %r25, %r8;
	add.s32 	%r27, %r26, %r8;
	add.s32 	%r30, %r27, %r8;
	add.s32 	%r9, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_20_20(
	.param .u64 .ptr .global .align 8 Double_addition_20_20_param_0,
	.param .u32 Double_addition_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_20_20_param_0];
	ld.param.u32 	%r4, [Double_addition_20_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd17, %fd16, %fd25;
	add.f64 	%fd18, %fd17, %fd25;
	add.f64 	%fd19, %fd18, %fd25;
	add.f64 	%fd20, %fd19, %fd25;
	add.f64 	%fd21, %fd20, %fd25;
	add.f64 	%fd22, %fd21, %fd25;
	add.f64 	%fd23, %fd22, %fd25;
	add.f64 	%fd24, %fd23, %fd25;
	add.f64 	%fd27, %fd24, %fd25;
	add.f64 	%fd6, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_20_20(
	.param .u64 .ptr .global .align 4 Integer_multiplication_20_20_param_0,
	.param .u32 Integer_multiplication_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_20_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_20_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r20, %r19, %r8;
	mul.lo.s32 	%r21, %r20, %r8;
	mul.lo.s32 	%r22, %r21, %r8;
	mul.lo.s32 	%r23, %r22, %r8;
	mul.lo.s32 	%r24, %r23, %r8;
	mul.lo.s32 	%r25, %r24, %r8;
	mul.lo.s32 	%r26, %r25, %r8;
	mul.lo.s32 	%r27, %r26, %r8;
	mul.lo.s32 	%r30, %r27, %r8;
	mul.lo.s32 	%r9, %r30, %r8;
    shl.b32     %r8, %r8, 2;
    add.s32     %r8, %r8, 987654321;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_20_20(
	.param .u64 .ptr .global .align 8 Double_multiplication_20_20_param_0,
	.param .u32 Double_multiplication_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_20_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_20_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FEFFFFFFFFFFFF7;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd17, %fd16, %fd25;
	mul.f64 	%fd18, %fd17, %fd25;
	mul.f64 	%fd19, %fd18, %fd25;
	mul.f64 	%fd20, %fd19, %fd25;
	mul.f64 	%fd21, %fd20, %fd25;
	mul.f64 	%fd22, %fd21, %fd25;
	mul.f64 	%fd23, %fd22, %fd25;
	mul.f64 	%fd24, %fd23, %fd25;
	mul.f64 	%fd27, %fd24, %fd25;
	mul.f64 	%fd6, %fd27, %fd25;
	shr.b64     %fd25, %fd25, 10;
    add.f64     %fd25, %fd25, 0d3FEFFFFFFFFFFFF7;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_0_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_0_20_param_0,
	.param .u32 Integer_addition_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_0_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_0_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r9, %r9, %r8;
	add.s32 	%r10, %r10, %r8;
	add.s32 	%r11, %r11, %r8;
	add.s32 	%r12, %r12, %r8;
	add.s32 	%r13, %r13, %r8;
    add.s32 	%r14, %r14, %r8;
	add.s32 	%r15, %r15, %r8;
	add.s32 	%r16, %r16, %r8;
	add.s32 	%r17, %r17, %r8;
	add.s32 	%r18, %r18, %r8;
	add.s32 	%r19, %r19, %r8;
	add.s32 	%r20, %r20, %r8;
	add.s32 	%r21, %r21, %r8;
	add.s32 	%r22, %r22, %r8;
	add.s32 	%r23, %r23, %r8;
	add.s32 	%r24, %r24, %r8;
	add.s32 	%r25, %r25, %r8;
	add.s32 	%r26, %r26, %r8;
	add.s32 	%r27, %r27, %r8;
	add.s32 	%r30, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_0_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_0_20_param_0,
	.param .u32 Double_addition_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_0_20_param_0];
	ld.param.u32 	%r4, [Double_addition_0_20_param_1];
    ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd6, %fd6, %fd25;
	add.f64 	%fd7, %fd7, %fd25;
	add.f64 	%fd8, %fd8, %fd25;
	add.f64 	%fd9, %fd9, %fd25;
	add.f64 	%fd10, %fd10, %fd25;
	add.f64 	%fd11, %fd11, %fd25;
	add.f64 	%fd12, %fd12, %fd25;
	add.f64 	%fd13, %fd13, %fd25;
	add.f64 	%fd14, %fd14, %fd25;
	add.f64 	%fd15, %fd15, %fd25;
	add.f64 	%fd16, %fd16, %fd25;
	add.f64 	%fd17, %fd17, %fd25;
	add.f64 	%fd18, %fd18, %fd25;
	add.f64 	%fd19, %fd19, %fd25;
	add.f64 	%fd20, %fd20, %fd25;
	add.f64 	%fd21, %fd21, %fd25;
	add.f64 	%fd22, %fd22, %fd25;
	add.f64 	%fd23, %fd23, %fd25;
	add.f64 	%fd24, %fd24, %fd25;
	add.f64 	%fd27, %fd27, %fd25;
    shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_0_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_0_20_param_0,
	.param .u32 Integer_multiplication_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_0_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_0_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r9, %r9, %r8;
	mul.lo.s32 	%r10, %r10, %r8;
	mul.lo.s32 	%r11, %r11, %r8;
	mul.lo.s32 	%r12, %r12, %r8;
	mul.lo.s32 	%r13, %r13, %r8;
    mul.lo.s32 	%r14, %r14, %r8;
	mul.lo.s32 	%r15, %r15, %r8;
	mul.lo.s32 	%r16, %r16, %r8;
	mul.lo.s32 	%r17, %r17, %r8;
	mul.lo.s32 	%r18, %r18, %r8;
	mul.lo.s32 	%r19, %r19, %r8;
	mul.lo.s32 	%r20, %r20, %r8;
	mul.lo.s32 	%r21, %r21, %r8;
	mul.lo.s32 	%r22, %r22, %r8;
	mul.lo.s32 	%r23, %r23, %r8;
	mul.lo.s32 	%r24, %r24, %r8;
	mul.lo.s32 	%r25, %r25, %r8;
	mul.lo.s32 	%r26, %r26, %r8;
	mul.lo.s32 	%r27, %r27, %r8;
	mul.lo.s32 	%r30, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_0_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_0_20_param_0,
	.param .u32 Double_multiplication_0_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_0_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_0_20_param_1];
    ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd6, %fd6, %fd25;
	mul.f64 	%fd7, %fd7, %fd25;
	mul.f64 	%fd8, %fd8, %fd25;
	mul.f64 	%fd9, %fd9, %fd25;
	mul.f64 	%fd10, %fd10, %fd25;
	mul.f64 	%fd11, %fd11, %fd25;
	mul.f64 	%fd12, %fd12, %fd25;
	mul.f64 	%fd13, %fd13, %fd25;
	mul.f64 	%fd14, %fd14, %fd25;
	mul.f64 	%fd15, %fd15, %fd25;
	mul.f64 	%fd16, %fd16, %fd25;
	mul.f64 	%fd17, %fd17, %fd25;
	mul.f64 	%fd18, %fd18, %fd25;
	mul.f64 	%fd19, %fd19, %fd25;
	mul.f64 	%fd20, %fd20, %fd25;
	mul.f64 	%fd21, %fd21, %fd25;
	mul.f64 	%fd22, %fd22, %fd25;
	mul.f64 	%fd23, %fd23, %fd25;
	mul.f64 	%fd24, %fd24, %fd25;
	mul.f64 	%fd27, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_5_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_5_20_param_0,
	.param .u32 Integer_addition_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_5_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_5_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r13, %r9, %r8;
	add.s32 	%r14, %r10, %r8;
	add.s32 	%r15, %r11, %r8;
	add.s32 	%r16, %r12, %r8;
	add.s32 	%r17, %r13, %r8;
    add.s32 	%r18, %r14, %r8;
	add.s32 	%r19, %r15, %r8;
	add.s32 	%r20, %r16, %r8;
	add.s32 	%r21, %r17, %r8;
	add.s32 	%r22, %r18, %r8;
	add.s32 	%r23, %r19, %r8;
	add.s32 	%r24, %r20, %r8;
	add.s32 	%r25, %r21, %r8;
	add.s32 	%r26, %r22, %r8;
	add.s32 	%r27, %r23, %r8;
	add.s32 	%r30, %r24, %r8;
	add.s32 	%r9, %r25, %r8;
	add.s32 	%r10, %r26, %r8;
	add.s32 	%r11, %r27, %r8;
	add.s32 	%r12, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_5_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_5_20_param_0,
	.param .u32 Double_addition_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_5_20_param_0];
	ld.param.u32 	%r4, [Double_addition_5_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd10, %fd6, %fd25;
	add.f64 	%fd11, %fd7, %fd25;
	add.f64 	%fd12, %fd8, %fd25;
	add.f64 	%fd13, %fd9, %fd25;
	add.f64 	%fd14, %fd10, %fd25;
	add.f64 	%fd15, %fd11, %fd25;
	add.f64 	%fd16, %fd12, %fd25;
	add.f64 	%fd17, %fd13, %fd25;
	add.f64 	%fd18, %fd14, %fd25;
	add.f64 	%fd19, %fd15, %fd25;
	add.f64 	%fd20, %fd16, %fd25;
	add.f64 	%fd21, %fd17, %fd25;
	add.f64 	%fd22, %fd18, %fd25;
	add.f64 	%fd23, %fd19, %fd25;
	add.f64 	%fd24, %fd20, %fd25;
	add.f64 	%fd27, %fd21, %fd25;
	add.f64 	%fd6, %fd22, %fd25;
	add.f64 	%fd7, %fd23, %fd25;
	add.f64 	%fd8, %fd24, %fd25;
	add.f64 	%fd9, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_5_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_5_20_param_0,
	.param .u32 Integer_multiplication_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_5_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_5_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r13, %r9, %r8;
	mul.lo.s32 	%r14, %r10, %r8;
	mul.lo.s32 	%r15, %r11, %r8;
	mul.lo.s32 	%r16, %r12, %r8;
	mul.lo.s32 	%r17, %r13, %r8;
    mul.lo.s32 	%r18, %r14, %r8;
	mul.lo.s32 	%r19, %r15, %r8;
	mul.lo.s32 	%r20, %r16, %r8;
	mul.lo.s32 	%r21, %r17, %r8;
	mul.lo.s32 	%r22, %r18, %r8;
	mul.lo.s32 	%r23, %r19, %r8;
	mul.lo.s32 	%r24, %r20, %r8;
	mul.lo.s32 	%r25, %r21, %r8;
	mul.lo.s32 	%r26, %r22, %r8;
	mul.lo.s32 	%r27, %r23, %r8;
	mul.lo.s32 	%r30, %r24, %r8;
	mul.lo.s32 	%r9, %r25, %r8;
	mul.lo.s32 	%r10, %r26, %r8;
	mul.lo.s32 	%r11, %r27, %r8;
	mul.lo.s32 	%r12, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_5_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_5_20_param_0,
	.param .u32 Double_multiplication_5_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_5_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_5_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd10, %fd6, %fd25;
	mul.f64 	%fd11, %fd7, %fd25;
	mul.f64 	%fd12, %fd8, %fd25;
	mul.f64 	%fd13, %fd9, %fd25;
	mul.f64 	%fd14, %fd10, %fd25;
	mul.f64 	%fd15, %fd11, %fd25;
	mul.f64 	%fd16, %fd12, %fd25;
	mul.f64 	%fd17, %fd13, %fd25;
	mul.f64 	%fd18, %fd14, %fd25;
	mul.f64 	%fd19, %fd15, %fd25;
	mul.f64 	%fd20, %fd16, %fd25;
	mul.f64 	%fd21, %fd17, %fd25;
	mul.f64 	%fd22, %fd18, %fd25;
	mul.f64 	%fd23, %fd19, %fd25;
	mul.f64 	%fd24, %fd20, %fd25;
	mul.f64 	%fd27, %fd21, %fd25;
	mul.f64 	%fd6, %fd22, %fd25;
	mul.f64 	%fd7, %fd23, %fd25;
	mul.f64 	%fd8, %fd24, %fd25;
	mul.f64 	%fd9, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_7_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_7_20_param_0,
	.param .u32 Integer_addition_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_7_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_7_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r11, %r9, %r8;
	add.s32 	%r12, %r10, %r8;
	add.s32 	%r13, %r11, %r8;
	add.s32 	%r14, %r12, %r8;
	add.s32 	%r15, %r13, %r8;
    add.s32 	%r16, %r14, %r8;
	add.s32 	%r17, %r15, %r8;
	add.s32 	%r18, %r16, %r8;
	add.s32 	%r19, %r17, %r8;
	add.s32 	%r20, %r18, %r8;
	add.s32 	%r24, %r19, %r8;
	add.s32 	%r25, %r20, %r8;
	add.s32 	%r26, %r21, %r8;
	add.s32 	%r27, %r22, %r8;
	add.s32 	%r30, %r23, %r8;
	add.s32 	%r9, %r24, %r8;
	add.s32 	%r10, %r25, %r8;
	add.s32 	%r11, %r26, %r8;
	add.s32 	%r12, %r27, %r8;
	add.s32 	%r13, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_7_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_7_20_param_0,
	.param .u32 Double_addition_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_7_20_param_0];
	ld.param.u32 	%r4, [Double_addition_7_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd8, %fd6, %fd25;
	add.f64 	%fd9, %fd7, %fd25;
	add.f64 	%fd10, %fd8, %fd25;
	add.f64 	%fd11, %fd9, %fd25;
	add.f64 	%fd12, %fd10, %fd25;
	add.f64 	%fd13, %fd11, %fd25;
	add.f64 	%fd14, %fd12, %fd25;
	add.f64 	%fd15, %fd13, %fd25;
	add.f64 	%fd16, %fd14, %fd25;
	add.f64 	%fd17, %fd15, %fd25;
	add.f64 	%fd21, %fd16, %fd25;
	add.f64 	%fd22, %fd17, %fd25;
	add.f64 	%fd23, %fd18, %fd25;
	add.f64 	%fd24, %fd19, %fd25;
	add.f64 	%fd27, %fd20, %fd25;
	add.f64 	%fd6, %fd21, %fd25;
	add.f64 	%fd7, %fd22, %fd25;
	add.f64 	%fd8, %fd23, %fd25;
	add.f64 	%fd9, %fd24, %fd25;
	add.f64 	%fd10, %fd27, %fd25;
    shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_7_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_7_20_param_0,
	.param .u32 Integer_multiplication_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_7_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_7_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r11, %r9, %r8;
	mul.lo.s32 	%r12, %r10, %r8;
	mul.lo.s32 	%r13, %r11, %r8;
	mul.lo.s32 	%r14, %r12, %r8;
	mul.lo.s32 	%r15, %r13, %r8;
    mul.lo.s32 	%r16, %r14, %r8;
	mul.lo.s32 	%r17, %r15, %r8;
	mul.lo.s32 	%r18, %r16, %r8;
	mul.lo.s32 	%r19, %r17, %r8;
	mul.lo.s32 	%r20, %r18, %r8;
	mul.lo.s32 	%r24, %r19, %r8;
	mul.lo.s32 	%r25, %r20, %r8;
	mul.lo.s32 	%r26, %r21, %r8;
	mul.lo.s32 	%r27, %r22, %r8;
	mul.lo.s32 	%r30, %r23, %r8;
	mul.lo.s32 	%r9, %r24, %r8;
	mul.lo.s32 	%r10, %r25, %r8;
	mul.lo.s32 	%r11, %r26, %r8;
	mul.lo.s32 	%r12, %r27, %r8;
	mul.lo.s32 	%r13, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_7_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_7_20_param_0,
	.param .u32 Double_multiplication_7_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_7_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_7_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
    setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd8, %fd6, %fd25;
	mul.f64 	%fd9, %fd7, %fd25;
	mul.f64 	%fd10, %fd8, %fd25;
	mul.f64 	%fd11, %fd9, %fd25;
	mul.f64 	%fd12, %fd10, %fd25;
	mul.f64 	%fd13, %fd11, %fd25;
	mul.f64 	%fd14, %fd12, %fd25;
	mul.f64 	%fd15, %fd13, %fd25;
	mul.f64 	%fd16, %fd14, %fd25;
	mul.f64 	%fd17, %fd15, %fd25;
	mul.f64 	%fd21, %fd16, %fd25;
	mul.f64 	%fd22, %fd17, %fd25;
	mul.f64 	%fd23, %fd18, %fd25;
	mul.f64 	%fd24, %fd19, %fd25;
	mul.f64 	%fd27, %fd20, %fd25;
	mul.f64 	%fd6, %fd21, %fd25;
	mul.f64 	%fd7, %fd22, %fd25;
	mul.f64 	%fd8, %fd23, %fd25;
	mul.f64 	%fd9, %fd24, %fd25;
	mul.f64 	%fd10, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_10_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_10_20_param_0,
	.param .u32 Integer_addition_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_10_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_10_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r11, %r9, %r8;
	add.s32 	%r12, %r10, %r8;
	add.s32 	%r13, %r11, %r8;
	add.s32 	%r14, %r12, %r8;
	add.s32 	%r15, %r13, %r8;
    add.s32 	%r16, %r14, %r8;
	add.s32 	%r17, %r15, %r8;
	add.s32 	%r18, %r16, %r8;
	add.s32 	%r19, %r17, %r8;
	add.s32 	%r20, %r18, %r8;
	add.s32 	%r21, %r19, %r8;
	add.s32 	%r22, %r20, %r8;
	add.s32 	%r23, %r21, %r8;
	add.s32 	%r24, %r22, %r8;
	add.s32 	%r25, %r23, %r8;
	add.s32 	%r26, %r24, %r8;
	add.s32 	%r27, %r25, %r8;
	add.s32 	%r30, %r26, %r8;
	add.s32 	%r9, %r27, %r8;
	add.s32 	%r10, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_10_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_10_20_param_0,
	.param .u32 Double_addition_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_10_20_param_0];
	ld.param.u32 	%r4, [Double_addition_10_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd8, %fd6, %fd25;
	add.f64 	%fd9, %fd7, %fd25;
	add.f64 	%fd10, %fd8, %fd25;
	add.f64 	%fd11, %fd9, %fd25;
	add.f64 	%fd12, %fd10, %fd25;
	add.f64 	%fd13, %fd11, %fd25;
	add.f64 	%fd14, %fd12, %fd25;
	add.f64 	%fd15, %fd13, %fd25;
	add.f64 	%fd16, %fd14, %fd25;
	add.f64 	%fd17, %fd15, %fd25;
	add.f64 	%fd18, %fd16, %fd25;
	add.f64 	%fd19, %fd17, %fd25;
	add.f64 	%fd20, %fd18, %fd25;
	add.f64 	%fd21, %fd19, %fd25;
	add.f64 	%fd22, %fd20, %fd25;
	add.f64 	%fd23, %fd21, %fd25;
	add.f64 	%fd24, %fd22, %fd25;
	add.f64 	%fd27, %fd23, %fd25;
	add.f64 	%fd6, %fd24, %fd25;
	add.f64 	%fd7, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_10_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_10_20_param_0,
	.param .u32 Integer_multiplication_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_10_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_10_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r11, %r9, %r8;
	mul.lo.s32 	%r12, %r10, %r8;
	mul.lo.s32 	%r13, %r11, %r8;
	mul.lo.s32 	%r14, %r12, %r8;
	mul.lo.s32 	%r15, %r13, %r8;
    mul.lo.s32 	%r16, %r14, %r8;
	mul.lo.s32 	%r17, %r15, %r8;
	mul.lo.s32 	%r18, %r16, %r8;
	mul.lo.s32 	%r19, %r17, %r8;
	mul.lo.s32 	%r20, %r18, %r8;
	mul.lo.s32 	%r21, %r19, %r8;
	mul.lo.s32 	%r22, %r20, %r8;
	mul.lo.s32 	%r23, %r21, %r8;
	mul.lo.s32 	%r24, %r22, %r8;
	mul.lo.s32 	%r25, %r23, %r8;
	mul.lo.s32 	%r26, %r24, %r8;
	mul.lo.s32 	%r27, %r25, %r8;
	mul.lo.s32 	%r30, %r26, %r8;
	mul.lo.s32 	%r9, %r27, %r8;
	mul.lo.s32 	%r10, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
    add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_10_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_10_20_param_0,
	.param .u32 Double_multiplication_10_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_10_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_10_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd8, %fd6, %fd25;
	mul.f64 	%fd9, %fd7, %fd25;
	mul.f64 	%fd10, %fd8, %fd25;
	mul.f64 	%fd11, %fd9, %fd25;
	mul.f64 	%fd12, %fd10, %fd25;
	mul.f64 	%fd13, %fd11, %fd25;
	mul.f64 	%fd14, %fd12, %fd25;
	mul.f64 	%fd15, %fd13, %fd25;
	mul.f64 	%fd16, %fd14, %fd25;
	mul.f64 	%fd17, %fd15, %fd25;
	mul.f64 	%fd18, %fd16, %fd25;
	mul.f64 	%fd19, %fd17, %fd25;
	mul.f64 	%fd20, %fd18, %fd25;
	mul.f64 	%fd21, %fd19, %fd25;
	mul.f64 	%fd22, %fd20, %fd25;
	mul.f64 	%fd23, %fd21, %fd25;
	mul.f64 	%fd24, %fd22, %fd25;
	mul.f64 	%fd27, %fd23, %fd25;
	mul.f64 	%fd6, %fd24, %fd25;
	mul.f64 	%fd7, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_12_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_12_20_param_0,
	.param .u32 Integer_addition_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_12_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_12_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r24, %r19, %r8;
	add.s32 	%r25, %r20, %r8;
	add.s32 	%r26, %r21, %r8;
	add.s32 	%r27, %r22, %r8;
	add.s32 	%r30, %r23, %r8;
	add.s32 	%r9, %r24, %r8;
	add.s32 	%r10, %r25, %r8;
	add.s32 	%r11, %r26, %r8;
	add.s32 	%r12, %r27, %r8;
	add.s32 	%r13, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_12_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_12_20_param_0,
	.param .u32 Double_addition_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_12_20_param_0];
	ld.param.u32 	%r4, [Double_addition_12_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd21, %fd16, %fd25;
	add.f64 	%fd22, %fd17, %fd25;
	add.f64 	%fd23, %fd18, %fd25;
	add.f64 	%fd24, %fd19, %fd25;
	add.f64 	%fd27, %fd20, %fd25;
	add.f64 	%fd6, %fd21, %fd25;
	add.f64 	%fd7, %fd22, %fd25;
	add.f64 	%fd8, %fd23, %fd25;
	add.f64 	%fd9, %fd24, %fd25;
	add.f64 	%fd10, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_12_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_12_20_param_0,
	.param .u32 Integer_multiplication_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_12_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_12_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r24, %r19, %r8;
	mul.lo.s32 	%r25, %r20, %r8;
	mul.lo.s32 	%r26, %r21, %r8;
	mul.lo.s32 	%r27, %r22, %r8;
	mul.lo.s32 	%r30, %r23, %r8;
	mul.lo.s32 	%r9, %r24, %r8;
	mul.lo.s32 	%r10, %r25, %r8;
	mul.lo.s32 	%r11, %r26, %r8;
	mul.lo.s32 	%r12, %r27, %r8;
	mul.lo.s32 	%r13, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_12_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_12_20_param_0,
	.param .u32 Double_multiplication_12_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_12_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_12_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd21, %fd16, %fd25;
	mul.f64 	%fd22, %fd17, %fd25;
	mul.f64 	%fd23, %fd18, %fd25;
	mul.f64 	%fd24, %fd19, %fd25;
	mul.f64 	%fd27, %fd20, %fd25;
	mul.f64 	%fd6, %fd21, %fd25;
	mul.f64 	%fd7, %fd22, %fd25;
	mul.f64 	%fd8, %fd23, %fd25;
	mul.f64 	%fd9, %fd24, %fd25;
	mul.f64 	%fd10, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_15_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_15_20_param_0,
	.param .u32 Integer_addition_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_15_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_15_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r21, %r19, %r8;
	add.s32 	%r22, %r20, %r8;
	add.s32 	%r23, %r21, %r8;
	add.s32 	%r24, %r22, %r8;
	add.s32 	%r25, %r23, %r8;
	add.s32 	%r26, %r24, %r8;
	add.s32 	%r27, %r25, %r8;
	add.s32 	%r30, %r26, %r8;
	add.s32 	%r9, %r27, %r8;
	add.s32 	%r10, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_15_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_15_20_param_0,
	.param .u32 Double_addition_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_15_20_param_0];
	ld.param.u32 	%r4, [Double_addition_15_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd18, %fd16, %fd25;
	add.f64 	%fd19, %fd17, %fd25;
	add.f64 	%fd20, %fd18, %fd25;
	add.f64 	%fd21, %fd19, %fd25;
	add.f64 	%fd22, %fd20, %fd25;
	add.f64 	%fd23, %fd21, %fd25;
	add.f64 	%fd24, %fd22, %fd25;
	add.f64 	%fd27, %fd23, %fd25;
	add.f64 	%fd6, %fd24, %fd25;
	add.f64 	%fd7, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_15_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_15_20_param_0,
	.param .u32 Integer_multiplication_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_15_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_15_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r21, %r19, %r8;
	mul.lo.s32 	%r22, %r20, %r8;
	mul.lo.s32 	%r23, %r21, %r8;
	mul.lo.s32 	%r24, %r22, %r8;
	mul.lo.s32 	%r25, %r23, %r8;
	mul.lo.s32 	%r26, %r24, %r8;
	mul.lo.s32 	%r27, %r25, %r8;
	mul.lo.s32 	%r30, %r26, %r8;
	mul.lo.s32 	%r9, %r27, %r8;
	mul.lo.s32 	%r10, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_15_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_15_20_param_0,
	.param .u32 Double_multiplication_15_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_15_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_15_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd18, %fd16, %fd25;
	mul.f64 	%fd19, %fd17, %fd25;
	mul.f64 	%fd20, %fd18, %fd25;
	mul.f64 	%fd21, %fd19, %fd25;
	mul.f64 	%fd22, %fd20, %fd25;
	mul.f64 	%fd23, %fd21, %fd25;
	mul.f64 	%fd24, %fd22, %fd25;
	mul.f64 	%fd27, %fd23, %fd25;
	mul.f64 	%fd6, %fd24, %fd25;
	mul.f64 	%fd7, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_addition_20_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_addition_20_20_param_0,
	.param .u32 Integer_addition_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_addition_20_20_param_0];
	ld.param.u32 	%r28, [Integer_addition_20_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	add.s32 	%r10, %r9, %r8;
	add.s32 	%r11, %r10, %r8;
	add.s32 	%r12, %r11, %r8;
	add.s32 	%r13, %r12, %r8;
	add.s32 	%r14, %r13, %r8;
    add.s32 	%r15, %r14, %r8;
	add.s32 	%r16, %r15, %r8;
	add.s32 	%r17, %r16, %r8;
	add.s32 	%r18, %r17, %r8;
	add.s32 	%r19, %r18, %r8;
	add.s32 	%r20, %r19, %r8;
	add.s32 	%r21, %r20, %r8;
	add.s32 	%r22, %r21, %r8;
	add.s32 	%r23, %r22, %r8;
	add.s32 	%r24, %r23, %r8;
	add.s32 	%r25, %r24, %r8;
	add.s32 	%r26, %r25, %r8;
	add.s32 	%r27, %r26, %r8;
	add.s32 	%r30, %r27, %r8;
	add.s32 	%r9, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_addition_20_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_addition_20_20_param_0,
	.param .u32 Double_addition_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_addition_20_20_param_0];
	ld.param.u32 	%r4, [Double_addition_20_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, %fd6;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	add.f64 	%fd7, %fd6, %fd25;
	add.f64 	%fd8, %fd7, %fd25;
	add.f64 	%fd9, %fd8, %fd25;
	add.f64 	%fd10, %fd9, %fd25;
	add.f64 	%fd11, %fd10, %fd25;
	add.f64 	%fd12, %fd11, %fd25;
	add.f64 	%fd13, %fd12, %fd25;
	add.f64 	%fd14, %fd13, %fd25;
	add.f64 	%fd15, %fd14, %fd25;
	add.f64 	%fd16, %fd15, %fd25;
	add.f64 	%fd17, %fd16, %fd25;
	add.f64 	%fd18, %fd17, %fd25;
	add.f64 	%fd19, %fd18, %fd25;
	add.f64 	%fd20, %fd19, %fd25;
	add.f64 	%fd21, %fd20, %fd25;
	add.f64 	%fd22, %fd21, %fd25;
	add.f64 	%fd23, %fd22, %fd25;
	add.f64 	%fd24, %fd23, %fd25;
	add.f64 	%fd27, %fd24, %fd25;
	add.f64 	%fd6, %fd27, %fd25;
	shl.b64     %fd25, %fd25, 10;
	add.f64     %fd25, %fd25, 0d41D26580B486522C;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}

.entry Integer_multiplication_20_20_dep_free(
	.param .u64 .ptr .global .align 4 Integer_multiplication_20_20_param_0,
	.param .u32 Integer_multiplication_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Integer_multiplication_20_20_param_0];
	ld.param.u32 	%r28, [Integer_multiplication_20_20_param_1];
	ld.global.u32 	%r9, [%rd1];
	ld.global.u32 	%r10, [%rd1+4];
	ld.global.u32 	%r11, [%rd1+8];
	ld.global.u32 	%r12, [%rd1+12];
	ld.global.u32 	%r13, [%rd1+16];
	ld.global.u32 	%r14, [%rd1+20];
	ld.global.u32 	%r15, [%rd1+24];
	ld.global.u32 	%r16, [%rd1+28];
	ld.global.u32 	%r17, [%rd1+32];
	ld.global.u32 	%r18, [%rd1+36];
	ld.global.u32 	%r19, [%rd1+40];
	ld.global.u32 	%r20, [%rd1+44];
	ld.global.u32 	%r21, [%rd1+48];
	ld.global.u32 	%r22, [%rd1+52];
	ld.global.u32 	%r23, [%rd1+56];
	ld.global.u32 	%r24, [%rd1+60];
	ld.global.u32 	%r25, [%rd1+64];
	ld.global.u32 	%r26, [%rd1+68];
	ld.global.u32 	%r27, [%rd1+72];
	ld.global.u32 	%r30, [%rd1+76];
	mov.s32      %r8, %r9;
    setp.lt.s32	%p1, %r28, 1;
	@%p1 bra 	BB0_2;

BB0_1:
	mul.lo.s32 	%r10, %r9, %r8;
	mul.lo.s32 	%r11, %r10, %r8;
	mul.lo.s32 	%r12, %r11, %r8;
	mul.lo.s32 	%r13, %r12, %r8;
	mul.lo.s32 	%r14, %r13, %r8;
    mul.lo.s32 	%r15, %r14, %r8;
	mul.lo.s32 	%r16, %r15, %r8;
	mul.lo.s32 	%r17, %r16, %r8;
	mul.lo.s32 	%r18, %r17, %r8;
	mul.lo.s32 	%r19, %r18, %r8;
	mul.lo.s32 	%r20, %r19, %r8;
	mul.lo.s32 	%r21, %r20, %r8;
	mul.lo.s32 	%r22, %r21, %r8;
	mul.lo.s32 	%r23, %r22, %r8;
	mul.lo.s32 	%r24, %r23, %r8;
	mul.lo.s32 	%r25, %r24, %r8;
	mul.lo.s32 	%r26, %r25, %r8;
	mul.lo.s32 	%r27, %r26, %r8;
	mul.lo.s32 	%r30, %r27, %r8;
	mul.lo.s32 	%r9, %r30, %r8;
    add.s32     %r8, %r8, 1234567890;
	add.s32 	%r28, %r28, -1;
    setp.gt.s32	%p2, %r28, 0;
	@%p2 bra 	BB0_1;

BB0_2:
	st.global.u32 	[%rd1], %r9;
	st.global.u32 	[%rd1+4], %r10;
	st.global.u32 	[%rd1+8], %r11;
	st.global.u32 	[%rd1+12], %r12;
	st.global.u32 	[%rd1+16], %r13;
	st.global.u32 	[%rd1+20], %r14;
	st.global.u32 	[%rd1+24], %r15;
	st.global.u32 	[%rd1+28], %r16;
	st.global.u32 	[%rd1+32], %r17;
	st.global.u32 	[%rd1+36], %r18;
	st.global.u32 	[%rd1+40], %r19;
	st.global.u32 	[%rd1+44], %r20;
	st.global.u32 	[%rd1+48], %r21;
	st.global.u32 	[%rd1+52], %r22;
	st.global.u32 	[%rd1+56], %r23;
	st.global.u32 	[%rd1+60], %r24;
	st.global.u32 	[%rd1+64], %r25;
	st.global.u32 	[%rd1+68], %r26;
	st.global.u32 	[%rd1+72], %r27;
	st.global.u32 	[%rd1+76], %r30;
	ret;
}

.entry Double_multiplication_20_20_dep_free(
	.param .u64 .ptr .global .align 8 Double_multiplication_20_20_param_0,
	.param .u32 Double_multiplication_20_20_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<5>;
	.reg .f64 	%fd<28>;
	.reg .b64 	%rd<2>;


	ld.param.u64 	%rd1, [Double_multiplication_20_20_param_0];
	ld.param.u32 	%r4, [Double_multiplication_20_20_param_1];
	ld.global.f64 	%fd6, [%rd1];
	ld.global.f64 	%fd7, [%rd1+8];
	ld.global.f64 	%fd8, [%rd1+16];
	ld.global.f64 	%fd9, [%rd1+24];
	ld.global.f64 	%fd10, [%rd1+32];
	ld.global.f64 	%fd11, [%rd1+40];
	ld.global.f64 	%fd12, [%rd1+48];
	ld.global.f64 	%fd13, [%rd1+56];
	ld.global.f64 	%fd14, [%rd1+64];
	ld.global.f64 	%fd15, [%rd1+72];
	ld.global.f64 	%fd16, [%rd1+80];
	ld.global.f64 	%fd17, [%rd1+88];
	ld.global.f64 	%fd18, [%rd1+96];
	ld.global.f64 	%fd19, [%rd1+104];
	ld.global.f64 	%fd20, [%rd1+112];
	ld.global.f64 	%fd21, [%rd1+120];
	ld.global.f64 	%fd22, [%rd1+128];
	ld.global.f64 	%fd23, [%rd1+136];
	ld.global.f64 	%fd24, [%rd1+144];
	ld.global.f64 	%fd27, [%rd1+152];
	mov.f64 	%fd25, 0d3FF0000000000038;
	setp.lt.s32	%p1, %r4, 1;
	@%p1 bra 	BB2_2;

BB2_1:
	mul.f64 	%fd7, %fd6, %fd25;
	mul.f64 	%fd8, %fd7, %fd25;
	mul.f64 	%fd9, %fd8, %fd25;
	mul.f64 	%fd10, %fd9, %fd25;
	mul.f64 	%fd11, %fd10, %fd25;
	mul.f64 	%fd12, %fd11, %fd25;
	mul.f64 	%fd13, %fd12, %fd25;
	mul.f64 	%fd14, %fd13, %fd25;
	mul.f64 	%fd15, %fd14, %fd25;
	mul.f64 	%fd16, %fd15, %fd25;
	mul.f64 	%fd17, %fd16, %fd25;
	mul.f64 	%fd18, %fd17, %fd25;
	mul.f64 	%fd19, %fd18, %fd25;
	mul.f64 	%fd20, %fd19, %fd25;
	mul.f64 	%fd21, %fd20, %fd25;
	mul.f64 	%fd22, %fd21, %fd25;
	mul.f64 	%fd23, %fd22, %fd25;
	mul.f64 	%fd24, %fd23, %fd25;
	mul.f64 	%fd27, %fd24, %fd25;
	mul.f64 	%fd6, %fd27, %fd25;
    add.f64     %fd25, %fd25, 0d3D0BCC6871D9240A;
    add.s32 	%r4, %r4, -1;
	setp.gt.s32	%p2, %r4, 0;
	@%p2 bra 	BB2_1;

BB2_2:
	st.global.f64 	[%rd1], %fd6;
	st.global.f64 	[%rd1+8], %fd7;
	st.global.f64 	[%rd1+16], %fd8;
	st.global.f64 	[%rd1+24], %fd9;
	st.global.f64 	[%rd1+32], %fd10;
	st.global.f64 	[%rd1+40], %fd11;
	st.global.f64 	[%rd1+48], %fd12;
	st.global.f64 	[%rd1+56], %fd13;
	st.global.f64 	[%rd1+64], %fd14;
	st.global.f64 	[%rd1+72], %fd15;
	st.global.f64 	[%rd1+80], %fd16;
	st.global.f64 	[%rd1+88], %fd17;
	st.global.f64 	[%rd1+96], %fd18;
	st.global.f64 	[%rd1+104], %fd19;
	st.global.f64 	[%rd1+112], %fd20;
	st.global.f64 	[%rd1+120], %fd21;
	st.global.f64 	[%rd1+128], %fd22;
	st.global.f64 	[%rd1+136], %fd23;
	st.global.f64 	[%rd1+144], %fd24;
	st.global.f64 	[%rd1+152], %fd27;
	ret;
}
